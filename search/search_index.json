{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AWS SERVELESS APPLICATION S3, LAMBDA, API GATEWAY E CLOUDWATCH","text":"Sobre o Desenvolvedor Github <pre>\nAluno: Lister Ogusuku Ribeiro\nContato: listeror@al.insper.edu.br\nCurso: Engenharia de Computa\u00e7\u00e3o\nDisciplina: Computa\u00e7\u00e3o em Nuvem\nSemestre: 6\u00ba (2023.1)\nProf\u00ba: Rodolfo Avelino\nProf\u00ba Auxiliar: Tiago Demay\n</pre> Lister OgusukuDeveloper"},{"location":"#cloud-computing-computacao-em-nuvem","title":"Cloud Computing (Computa\u00e7\u00e3o em Nuvem)","text":"<p>A computa\u00e7\u00e3o em nuvem \u00e9 um modelo de tecnologia de informa\u00e7\u00e3o que permite o acesso sob demanda a um conjunto compartilhado de recursos de computa\u00e7\u00e3o, como servidores, armazenamento, aplicativos e servi\u00e7os, por meio da internet. Em outras palavras, a computa\u00e7\u00e3o em nuvem \u00e9 uma forma de disponibilizar recursos computacionais atrav\u00e9s da internet, em vez de ter todos os recursos armazenados localmente em um \u00fanico computador ou servidor. Esses recursos s\u00e3o gerenciados e mantidos por provedores de servi\u00e7os em nuvem, como a Amazon Web Services, Microsoft Azure e Google Cloud Platform.</p> <p>A computa\u00e7\u00e3o em nuvem pode ser utilizada para diversas finalidades, como armazenar arquivos e documentos, hospedar aplicativos, desenvolver e testar software, processar dados em larga escala, entre outras. A principal vantagem da computa\u00e7\u00e3o em nuvem \u00e9 que ela permite que as empresas e usu\u00e1rios finais utilizem recursos computacionais de forma flex\u00edvel e escal\u00e1vel, sem precisar investir em infraestrutura de TI pr\u00f3pria. Al\u00e9m disso, a computa\u00e7\u00e3o em nuvem oferece maior disponibilidade e seguran\u00e7a de dados do que solu\u00e7\u00f5es locais, j\u00e1 que os provedores de servi\u00e7os em nuvem costumam ter data centers redundantes e medidas de seguran\u00e7a avan\u00e7adas para proteger os dados dos usu\u00e1rios.</p> <p></p>"},{"location":"#sobre-o-projeto","title":"Sobre o Projeto","text":"<p>O Projeto a seguir visa aplicar conceitos de Computa\u00e7\u00e3o em Nuvem (Cloud Computing) por meio da plataforma de servi\u00e7os de Computa\u00e7\u00e3o em Nuvem AWS (Amazon Web Services). A ideia \u00e9 subir uma aplica\u00e7\u00e3o sem servidor na AWS utilizando o S3, Lambda, API Gateway e o CloudWatch colocando em pr\u00e1tica os conceitos de IaaC (Infrastructure as a Code). O diagrama visual da nossa aplica\u00e7\u00e3o pode ser conferido a seguir:</p>"},{"location":"#desenvolvendo-a-infraestrutura","title":"Desenvolvendo a infraestrutura","text":""},{"location":"#1-pre-requisitos","title":"1. Pr\u00e9-requisitos","text":"<ul> <li> <p>Para rodar nossa infraestrutura, estamos utilizando o Ubuntu 22.04.2 LTS (o qual j\u00e1 estava instalado no nosso Windows). A infra pode funcionar em outras vers\u00f5es, por\u00e9m n\u00e3o h\u00e1 garantia de funcionamento. Assim sendo, indicamos o uso da vers\u00e3o supracitada para testar nossa aplica\u00e7\u00e3o (ou at\u00e9 mesmo rodar a sua pr\u00f3pria).</p> </li> <li> <p>Conta no Github + token de autoriza\u00e7\u00e3o com permiss\u00e3o de cria\u00e7\u00e3o e atualiza\u00e7\u00e3o de reposit\u00f3rios (caso voc\u00ea desejar subir e deixar o projeto registrado).</p> </li> <li> <p>Node.js instalado na m\u00e1quina. (no caso, instalamos diretamente dentro do Ubuntu 22.04.2 LTS via terminal).</p> </li> <li> <p>Conta na AWS com usu\u00e1rio com permiss\u00f5es de Administrador.</p> </li> <li> <p>Terraform instalado na m\u00e1quina (no caso, instalamos diretamente dentro do Ubuntu 22.04.2 LTS).</p> </li> <li> <p>Visual Studio Code (VS Code).</p> </li> </ul>"},{"location":"#2-instalacao-do-terraform","title":"2. Instala\u00e7\u00e3o do Terraform","text":"<p>A primeira etapa para desenvolvermos essa aplica\u00e7\u00e3o \u00e9 instalar o Terraform na m\u00e1quina. O Terraform \u00e9 uma ferramenta de gerenciamento de infraestrutura como c\u00f3digo (IaC) desenvolvida pela HashiCorp. Ele permite que os usu\u00e1rios definam, configurem e provisionem infraestruturas de forma automatizada e reprodut\u00edvel, usando uma linguagem declarativa e uma sintaxe simples. Com o Terraform, \u00e9 poss\u00edvel criar e gerenciar recursos em diferentes provedores de nuvem, como AWS, Google Cloud, Azure e outros, bem como em plataformas de infraestrutura, como Kubernetes, Docker e OpenStack. Em resumo, o Terraform \u00e9 uma ferramenta importante para automatizar e gerenciar infraestruturas de nuvem e outras plataformas de infraestrutura, tornando a gest\u00e3o de infraestrutura escal\u00e1vel, segura e repet\u00edvel.</p> <p>Caso voc\u00ea n\u00e3o possua o Terraform no seu computador, \u00e9 necess\u00e1rio baixar e instalar de acordo com o tutorial presente neste link (Windows) ou diretamente neste link (Ubuntu/Linux).</p>"},{"location":"#3-utilizacao","title":"3. Utiliza\u00e7\u00e3o","text":"<p>Ap\u00f3s a instala\u00e7\u00e3o do Terraform na m\u00e1quina, j\u00e1 \u00e9 poss\u00edvel rodar a infraestrutura desenvolvida ou criar sua pr\u00f3pria infraestrutura com base em tudo que est\u00e1 sendo apresentado aqui.</p> <p>O primeiro passo \u00e9 clonar este reposit\u00f3rio em uma pasta dentro do seu computador. Caso n\u00e3o saiba como clonar um reposit\u00f3rio na sua m\u00e1quina local, acesse o tutorial presente neste link ou fa\u00e7a o download do resposit\u00f3rio e descompacte o arquivo .zip no local desejado.</p> <p>Tip</p> <p>Caso voc\u00ea desejar criar a infraestrutura do zero, segui e sugiro a seguinte estrutura de pastas:</p> <pre><code>Cloud-Project\n\u2502\n\u2502\n\u2514\u2500\u2500\u2500hello\n\u2502   |---function.js\n\u2502\n\u2514\u2500\u2500\u2500s3\n|   \u2502---function.js\n\u2502\n\u2502\u2500\u2500\u2500Terraform\n\u2502   |---api-gateway.tf\n\u2502   |\n\u2502   |---hello-api-gateway.tf\n\u2502   |\n\u2502   |---hello-lamba.tf\n\u2502   |\n\u2502   |---lambda-s3-bucket.tf\n\u2502   |\n\u2502   |---provider.tf\n\u2502   |\n\u2502   |---s3-lambda.tf\n\u2502   |\n\u2502   |---test-bucket.tf\n\u2502   |\n\u2502   |---terraform.sh\n</code></pre> <p>Independentemente se voc\u00ea escolheu clonar o reposit\u00f3rio com a infraestrutura original ou se tiver escolhido criar do zero, lembre-se que tudo deve ser feito dentro do prompt de comando do Ubuntu 22.04.2 LTS caso deseje chegar nos mesmos resultados apresentados aqui sem grandes riscos de problemas.</p>"},{"location":"#credenciais-aws-no-terraform","title":"Credenciais AWS no Terraform","text":"<p>Antes de darmos in\u00edcio, \u00e9 necess\u00e1rio cadastrar suas credenciais AWS na sua m\u00e1quina. Temos v\u00e1rias formas de fazer isso, por\u00e9m iremos optar pela alternativa que eu considero mais segura para quem est\u00e1 iniciando na AWS (incluindo eu mesmo): cadastrar diretamente via terminal. Voc\u00ea deve possuir um .csv com a chave de acesso (Secret Key) e a chave secreta (Secret Access Key) de acesso da sua conta, precisaremos dessas informa\u00e7\u00f5es agora. Dentro do terminal Ubuntu, insira os comandos:</p> <pre><code>aws configure\n</code></pre> <p>Ap\u00f3s o comando acima, ser\u00e3o solicitadas as suas chaves de acesso. Coloque-as no terminal como solicitado e bora trabalhar!</p>"},{"location":"#criando-uma-funcao-lambda-no-terraform","title":"Criando uma fun\u00e7\u00e3o Lambda no Terraform","text":"<p>O primeiro passo ser\u00e1 criarmos uma fun\u00e7\u00e3o lambda que, futuramente, ser\u00e1 integrada com o AWS API Gateway. Inicialmente, come\u00e7aremos com uma fun\u00e7\u00e3o simples baseada em NodeJS sem nenhuma depend\u00eancia.</p> index.js <pre><code>exports.handler = async (event) =&gt; {\nconsole.log(\"Event: \", event);\nlet responseMessage = \"Hello, World!\";\n\nif (event.queryStringParameters &amp;&amp; event.queryStringParameters[\"Name\"]) {\nresponseMessage = \"Hello, \" + event.queryStringParameters[\"Name\"] + \"!\";\n}\n\nreturn response;\n};\n</code></pre> <p>Ao invocar essa fun\u00e7\u00e3o com uma consulta de URL e com o par\u00e2metro Name definido, ela retornar\u00e1 \"Hello, Name!\".</p> index.js <pre><code>exports.handler = async (event) =&gt; {\nconsole.log(\"Event: \", event);\nlet responseMessage = \"Hello, World!\";\n\nif (event.queryStringParameters &amp;&amp; event.queryStringParameters[\"Name\"]) {\nresponseMessage = \"Hello, \" + event.queryStringParameters[\"Name\"] + \"!\";\n}\n\n+  if (event.httpMethod === \"POST\") {\n+    const body = JSON.parse(event.body);\n+    responseMessage = \"Hello, \" + body.name + \"!\";\n+  }\n\n+  const response = {\n+    statusCode: 200,\n+    headers: {\n+      \"Content-Type\": \"application/json\",\n+    },\n+    body: JSON.stringify({\n+      message: responseMessage,\n+    }),\n+  };\n\nreturn response;\n};\n</code></pre> <p>Tamb\u00e9m ser\u00e1 verificado o m\u00e9todo HTTP GET e POST para que seja verificada a resposta padr\u00e3o. Foi especificado o c\u00f3digo de status '200', tipo de conte\u00fado e a mensagem para ser retornada ao chamador.</p>"},{"location":"#criando-o-provider","title":"Criando o provider","text":"<p>Agora que nossa handler j\u00e1 est\u00e1 pronta, come\u00e7aremos a trabalhar em alguns elementos do nosso Terraform. Criaremos os arquivos .tf dentro de uma pasta intitulada (por motivos intuitivos, claro) como \"terraform\".</p> <p>Come\u00e7aremos criando o arquivo \"provider.tf\", em que ser\u00e3o declaradas as restri\u00e7\u00f5es de vers\u00e3o (regi\u00e3o da AWS, por exemplo) para os diferentes provedores AWS, vers\u00f5es de Teraform e afins.</p> <p>Isso \u00e9 feito apenas para que, caso algu\u00e9m pegue esse projeto no futuro e rode em outra vers\u00e3o de Terraform ou com configura\u00e7\u00f5es diferentes das que foram aqui padronizadas, o projeto n\u00e3o funcione.</p> terraform/provider.tf <pre><code>terraform {\nrequired_providers {\naws = {\nsource = \"hashicorp/aws\"\nversion = \"~&gt; 4.21.0\"\n}\n    # Aqui dentro poder\u00edamos tamb\u00e9m ter estabelecido outras restri\u00e7\u00f5es\n    # de vers\u00e3o, mas optei por deixar o mais simples poss\u00edvel.\n}\n\nrequired_version = \"~&gt; 1.0\"\n}\n\nprovider \"aws\" {\nregion = \"us-east-1\" # Regi\u00e3o Northern Virginia\n}\n</code></pre>"},{"location":"#bucket-do-s3","title":"Bucket do S3","text":"<p>Agora n\u00f3s construiremos uma fun\u00e7\u00e3o com todas as depend\u00eancias, empacotaremos como um arquivo zip para que, assim, consigamos subir num bucket do S3. Ou seja, quando criamos o lambda, apontamos para esse objeto de arquvo zip no bucket S3.</p> <p>Como os nomes dos buckets do S3 devem ser \u00fanicos e exclusivos no mundo inteiro, podemos utilizar um gerador aleat\u00f3rio para nos ajudar a nomear nosso bucket S3.</p> terraform/lambda-bucket.tf <pre><code>resource \"random_pet\" \"lambda_bucket_name\" {\nprefix = \"lambda\"\nlength = 2\n}\n</code></pre> <p>Em seguida, vamos criar o pr\u00f3prio bucket do S3 com o nome gerado.</p> terraform/lambda-bucket.tf <pre><code>resource \"random_pet\" \"lambda_bucket_name\" {\nprefix = \"lambda\"\nlength = 2\n}\n\n+resource \"aws_s3_bucket\" \"lambda_bucket\" {\n+  bucket        = random_pet.lambda_bucket_name.id\n+  force_destroy = true\n+}\n</code></pre> <p>Por padr\u00e3o, deixaremos todo o acesso p\u00fablico ao bucket bloqueado.</p> terraform/lambda-bucket.tf <pre><code>resource \"random_pet\" \"lambda_bucket_name\" {\nprefix = \"lambda\"\nlength = 2\n}\n\nresource \"aws_s3_bucket\" \"lambda_bucket\" {\nbucket        = random_pet.lambda_bucket_name.id\nforce_destroy = true\n}\n\n+resource \"aws_s3_bucket_public_access_block\" \"lambda_bucket\" {\n+  bucket = aws_s3_bucket.lambda_bucket.id\n\n+  block_public_acls       = true\n+  block_public_policy     = true\n+  ignore_public_acls      = true\n+  restrict_public_buckets = true\n+}\n</code></pre>"},{"location":"#iam-e-policies","title":"IAM e Policies","text":"<p>Agora criaremos o c\u00f3digo Terraform do lambda. Lembrando que o lambda exigir\u00e1 acesso a outros servi\u00e7os da AWS (como o CloudWatch, para gravar logs) e, no nosso caso, concederemos acesso ao bucket do S3 para que seja poss\u00edvel a leitura de um arquivo.</p> <p>Para isso, precisamos criar uma fun\u00e7\u00e3o do IAM e permitir que o lambda a use.</p> terraform/hello-lambda.tf <pre><code>resource \"aws_iam_role\" \"hello_lambda_exec\" {\nname = \"hello-lambda\"\n\nassume_role_policy = &lt;&lt;POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"hello_lambda_policy\" {\nrole       = aws_iam_role.hello_lambda_exec.name\npolicy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n</code></pre>"},{"location":"#criando-uma-funcao-lambda","title":"Criando uma fun\u00e7\u00e3o Lambda","text":"<p>O pr\u00f3ximo recurso ser\u00e1 criar a fun\u00e7\u00e3o lambda, a qual chamaremos de \"hello\". Em seguida especificaremos o nome do intervalo onde armazenaremos todos os lambdas. E nosso key pointing ir\u00e1 apontar para um arquivo zip com uma fun\u00e7\u00e3o.</p> <p>O hash do c\u00f3digo-fonte foi adicionado para reimplementar a fun\u00e7\u00e3o caso seja alterado/atualizado algo no c\u00f3digo-fonte. Se o hash do arquivo zip for diferente, a reimplanta\u00e7\u00e3o do lambda ser\u00e1 for\u00e7ada.</p> terraform/hello-lambda.tf <pre><code>resource \"aws_iam_role\" \"hello_lambda_exec\" {\nname = \"hello-lambda\"\n\nassume_role_policy = &lt;&lt;POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"hello_lambda_policy\" {\nrole       = aws_iam_role.hello_lambda_exec.name\npolicy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\n+resource \"aws_lambda_function\" \"hello\" {\n+  function_name = \"hello\"\n\n+  s3_bucket = aws_s3_bucket.lambda_bucket.id\n+  s3_key    = aws_s3_object.lambda_hello.key\n\n+  runtime = \"nodejs16.x\"\n+  handler = \"function.handler\"\n\n+  source_code_hash = data.archive_file.lambda_hello.output_base64sha256\n\n+  role = aws_iam_role.hello_lambda_exec.arn\n+}\n</code></pre>"},{"location":"#criando-o-cloudwatch","title":"Criando o CloudWatch","text":"<p>Para depurar, criamos um grupo de logs do CloudWatch que conseguisse armazenar todas as instru\u00e7\u00f5es e erros do console.log na fun\u00e7\u00e3o. Definimos a reten\u00e7\u00e3o para 30 dias, por\u00e9m poderia ser uma quantidade maior ou menor tamb\u00e9m, a depender das inten\u00e7\u00f5es de quem est\u00e1 desenvolvendo a infraestrutura (al\u00e9m dessas decis\u00f5es poderem afetar o custo de execu\u00e7\u00e3o do lambda).</p> terraform/hello-lambda.tf <pre><code>resource \"aws_iam_role\" \"hello_lambda_exec\" {\nname = \"hello-lambda\"\n\nassume_role_policy = &lt;&lt;POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"hello_lambda_policy\" {\nrole       = aws_iam_role.hello_lambda_exec.name\npolicy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_lambda_function\" \"hello\" {\nfunction_name = \"hello\"\n\ns3_bucket = aws_s3_bucket.lambda_bucket.id\ns3_key    = aws_s3_object.lambda_hello.key\n\nruntime = \"nodejs16.x\"\nhandler = \"function.handler\"\n\nsource_code_hash = data.archive_file.lambda_hello.output_base64sha256\n\nrole = aws_iam_role.hello_lambda_exec.arn\n}\n\n+resource \"aws_cloudwatch_log_group\" \"hello\" {\n+  name = \"/aws/lambda/${aws_lambda_function.hello.function_name}\"\n\n+  retention_in_days = 30\n+}\n</code></pre> <p>Em seguida, adicionaremos o recurso que empacota o lambda como um arquivo zip.</p> terraform/hello-lambda.tf <pre><code>resource \"aws_iam_role\" \"hello_lambda_exec\" {\nname = \"hello-lambda\"\n\nassume_role_policy = &lt;&lt;POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"hello_lambda_policy\" {\nrole       = aws_iam_role.hello_lambda_exec.name\npolicy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_lambda_function\" \"hello\" {\nfunction_name = \"hello\"\n\ns3_bucket = aws_s3_bucket.lambda_bucket.id\ns3_key    = aws_s3_object.lambda_hello.key\n\nruntime = \"nodejs16.x\"\nhandler = \"function.handler\"\n\nsource_code_hash = data.archive_file.lambda_hello.output_base64sha256\n\nrole = aws_iam_role.hello_lambda_exec.arn\n}\n\nresource \"aws_cloudwatch_log_group\" \"hello\" {\nname = \"/aws/lambda/${aws_lambda_function.hello.function_name}\"\n\nretention_in_days = 14\n}\n\n+data \"archive_file\" \"lambda_hello\" {\n+  type = \"zip\"\n\n+  source_dir  = \"../${path.module}/hello\"\n+  output_path = \"../${path.module}/hello.zip\"\n+}\n</code></pre> <p>Nosso \u00faltimo componente visa obter o arquivo zip e carregar no bucket do S3.</p> terraform/hello-lambda.tf <pre><code>resource \"aws_iam_role\" \"hello_lambda_exec\" {\nname = \"hello-lambda\"\n\nassume_role_policy = &lt;&lt;POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"hello_lambda_policy\" {\nrole       = aws_iam_role.hello_lambda_exec.name\npolicy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_lambda_function\" \"hello\" {\nfunction_name = \"hello\"\n\ns3_bucket = aws_s3_bucket.lambda_bucket.id\ns3_key    = aws_s3_object.lambda_hello.key\n\nruntime = \"nodejs16.x\"\nhandler = \"function.handler\"\n\nsource_code_hash = data.archive_file.lambda_hello.output_base64sha256\n\nrole = aws_iam_role.hello_lambda_exec.arn\n}\n\nresource \"aws_cloudwatch_log_group\" \"hello\" {\nname = \"/aws/lambda/${aws_lambda_function.hello.function_name}\"\n\nretention_in_days = 30\n}\n\ndata \"archive_file\" \"lambda_hello\" {\ntype = \"zip\"\n\nsource_dir  = \"../${path.module}/hello\"\noutput_path = \"../${path.module}/hello.zip\"\n}\n\n+resource \"aws_s3_object\" \"lambda_hello\" {\n+  bucket = aws_s3_bucket.lambda_bucket.id\n\n+  key    = \"hello.zip\"\n+  source = data.archive_file.lambda_hello.output_path\n\n+  etag = filemd5(data.archive_file.lambda_hello.output_path)\n+}\n</code></pre>"},{"location":"#inicializando-o-terraform","title":"Inicializando o Terraform","text":"<p>Com os passos feitos at\u00e9 aqui j\u00e1 conseguimos inicializar o terraform:</p> <pre><code>terraform init\n</code></pre> <p></p> <p>Agora aplicamos as altera\u00e7\u00f5es:</p> <p><pre><code>terraform apply\n</code></pre> </p> <p> Dica visual</p> <p>Quando o terraform concluir suas etapas at\u00e9 aqui, podemos entrar no dashboard da AWS e encontrar, dentre outras coisas, um bucket S3 rec\u00e9m-criado com um nome definido por meio de um gerador de animais de estima\u00e7\u00e3o aleat\u00f3rio.  </p> <p>Para abstrair:</p> <p>Note que dentro do bucket s\u00e3o armazenadas fun\u00e7\u00f5es lambdas dentro de um zip.</p> <p>Quando entramos na dashboard da AWS CloudWatch tamb\u00e9m conseguimos ver o grupo de logs criado.</p> <p></p> <p>No dashboard do AWS Lambda conseguimos ver a fun\u00e7\u00e3o lambda empacotada como um zip.</p> <p></p> <p>Vamos agora invocar a fun\u00e7\u00e3o com o comando aws lambda invoke.</p> <p>Lembre-se de especificar ou conferir se o nome da regi\u00e3o, fun\u00e7\u00e3o e arquivo est\u00e3o corretos para registrar a resposta da fun\u00e7\u00e3o.</p> <p><pre><code>aws lambda invoke --region=us-east-1 --function-name=hello response.json\n</code></pre>  Ao printarmos a resposta, \u00e9 esperado um retorno \"Ol\u00e1, Avelino!\"</p> <p><pre><code>cat response.json\n</code></pre> </p>"},{"location":"#criando-o-api-gateway","title":"Criando o API Gateway","text":"<p>A pr\u00f3xima estapa ser\u00e1 criar o API Gateway e integr\u00e1-lo ao nosso lambda.</p> <p>Utilizaremos a vers\u00e3o 2 do API Gateway.</p> terraform/api-gateway.tf <pre><code>resource \"aws_apigatewayv2_api\" \"main\" {\nname          = \"main\"\nprotocol_type = \"HTTP\"\n}\n\nresource \"aws_apigatewayv2_stage\" \"dev\" {\napi_id = aws_apigatewayv2_api.main.id\n\nname        = \"dev\"\nauto_deploy = true\n\naccess_log_settings {\ndestination_arn = aws_cloudwatch_log_group.main_api_gw.arn\n\nformat = jsonencode({\nrequestId               = \"$context.requestId\"\nsourceIp                = \"$context.identity.sourceIp\"\nrequestTime             = \"$context.requestTime\"\nprotocol                = \"$context.protocol\"\nhttpMethod              = \"$context.httpMethod\"\nresourcePath            = \"$context.resourcePath\"\nrouteKey                = \"$context.routeKey\"\nstatus                  = \"$context.status\"\nresponseLength          = \"$context.responseLength\"\nintegrationErrorMessage = \"$context.integrationErrorMessage\"\n}\n)\n}\n}\n\nresource \"aws_cloudwatch_log_group\" \"main_api_gw\" {\nname = \"/aws/api-gw/${aws_apigatewayv2_api.main.name}\"\n\nretention_in_days = 30\n}\n</code></pre>"},{"location":"#integrando-o-api-gateway-com-o-lambda","title":"Integrando o API Gateway com o Lambda","text":"<p>No pr\u00f3ximo arquivo Terraform, integraremos o API Gateway com o hello lambda. Primeiramente apontaremos para o ID do API Gateway que acabamos de criar. Em seguida utilizaremos PROXYS AWS e solicita\u00e7\u00f5es POST para encaminhar solicita\u00e7\u00f5es do API Gateway para o Lambda</p> terraform/hello-api-gateway.tf <pre><code>resource \"aws_apigatewayv2_integration\" \"lambda_hello\" {\napi_id = aws_apigatewayv2_api.main.id\n\nintegration_uri = aws_lambda_function.hello.invoke_arn\nintegration_type = \"AWS_PROXY\"\nintegration_method = \"POST\"\n}\n</code></pre> <p>Podemos especificar qual tipo de solicita\u00e7\u00f5es queremos passar para o lambda, por exemplo: GET ou POST, como abaixo:</p> terraform/hello-api-gateway.tf <pre><code>resource \"aws_apigatewayv2_integration\" \"lambda_hello\" {\napi_id = aws_apigatewayv2_api.main.id\n\nintegration_uri = aws_lambda_function.hello.invoke_arn\nintegration_type = \"AWS_PROXY\"\nintegration_method = \"POST\"\n}\n\n+resource \"aws_apigatewayv2_route\" \"get_hello\" {\n+api_id = aws_apigatewayv2_api.main.id\n\n+route_key = \"GET /hello\"\n+target = \"integrations/${aws_apigatewayv2_integration.lambda_hello.id}\"\n+}\n\n+resource \"aws_apigatewayv2_route\" \"post_hello\" {\n+api_id = aws_apigatewayv2_api.main.id\n\n+route_key = \"POST /hello\"\n+target = \"integrations/${aws_apigatewayv2_integration.lambda_hello.id}\"\n+}\n</code></pre> <p>Note que em ambos os exemplos \u00e9 necess\u00e1rio especificar um destino para ser o nosso lambda. Tamb\u00e9m precisamos conceder permiss\u00f5es ao API Gateway para invocar nossa fun\u00e7\u00e3o lambda:</p> terraform/hello-api-gateway.tf <pre><code>resource \"aws_apigatewayv2_integration\" \"lambda_hello\" {\napi_id = aws_apigatewayv2_api.main.id\n\nintegration_uri    = aws_lambda_function.hello.invoke_arn\nintegration_type   = \"AWS_PROXY\"\nintegration_method = \"POST\"\n}\n\nresource \"aws_apigatewayv2_route\" \"get_hello\" {\napi_id = aws_apigatewayv2_api.main.id\n\nroute_key = \"GET /hello\"\ntarget    = \"integrations/${aws_apigatewayv2_integration.lambda_hello.id}\"\n}\n\nresource \"aws_apigatewayv2_route\" \"post_hello\" {\napi_id = aws_apigatewayv2_api.main.id\n\nroute_key = \"POST /hello\"\ntarget    = \"integrations/${aws_apigatewayv2_integration.lambda_hello.id}\"\n}\n\n+resource \"aws_lambda_permission\" \"api_gw\" {\n+  statement_id  = \"AllowExecutionFromAPIGateway\"\n+  action        = \"lambda:InvokeFunction\"\n+  function_name = aws_lambda_function.hello.function_name\n+  principal     = \"apigateway.amazonaws.com\"\n\n+  source_arn = \"${aws_apigatewayv2_api.main.execution_arn}/*/*\"\n+}\n</code></pre>"},{"location":"#invocando-o-lambda","title":"Invocando o Lambda","text":"<p>Por fim, vamos imprimir no console o URL que podemos usar para invocar o lambda.</p> terraform/hello-api-gateway.tf <pre><code>resource \"aws_apigatewayv2_integration\" \"lambda_hello\" {\napi_id = aws_apigatewayv2_api.main.id\n\nintegration_uri    = aws_lambda_function.hello.invoke_arn\nintegration_type   = \"AWS_PROXY\"\nintegration_method = \"POST\"\n}\n\nresource \"aws_apigatewayv2_route\" \"get_hello\" {\napi_id = aws_apigatewayv2_api.main.id\n\nroute_key = \"GET /hello\"\ntarget    = \"integrations/${aws_apigatewayv2_integration.lambda_hello.id}\"\n}\n\nresource \"aws_apigatewayv2_route\" \"post_hello\" {\napi_id = aws_apigatewayv2_api.main.id\n\nroute_key = \"POST /hello\"\ntarget    = \"integrations/${aws_apigatewayv2_integration.lambda_hello.id}\"\n}\n\nresource \"aws_lambda_permission\" \"api_gw\" {\nstatement_id  = \"AllowExecutionFromAPIGateway\"\naction        = \"lambda:InvokeFunction\"\nfunction_name = aws_lambda_function.hello.function_name\nprincipal     = \"apigateway.amazonaws.com\"\n\nsource_arn = \"${aws_apigatewayv2_api.main.execution_arn}/*/*\"\n}\n\n+output \"hello_base_url\" {\n+  value = aws_apigatewayv2_stage.dev.invoke_url\n+}\n</code></pre> <p>No terminal, daremos um apply no terraform.</p> <p><pre><code>terraform apply\n</code></pre> </p> <p> Dica visual</p> <p>Se entrarmos no dashboard do API Gateway, podemos ver nosso est\u00e1gio de desenvolvimento \"dev\" criado e, em \"rotas\", conseguimos encontrar os m\u00e9todos GET e POST. </p> <p>At\u00e9 essa etapa, se voc\u00ea estiver seguindo a risca minha forma de fazer esse handout, \u00e9 esperada que a estrutura do seu c\u00f3digo esteja como na imagem abaixo:</p> <p></p>"},{"location":"#hora-de-testar","title":"Hora de testar","text":"<p>Vamos agora testar o m\u00e9todo HTTP GET. A fun\u00e7\u00e3o deve analis\u00e1-lo e retornar a mensagem \"Ol\u00e1, + par\u00e2metro de URL\"</p> <p><pre><code>curl \"https://&lt;id&gt;.execute-api.us-east-1.amazonaws.com/dev/hello?Name=InsperUniversity\"\n/\\\n               ||\nSubstitua &lt;id&gt; pelo seu id\n</code></pre> </p> <p>Tamb\u00e9m testaremos o m\u00e9todo POST. Nesse caso, fornecemos um payload como um objeto json para o terminal e veremos que funciona tamb\u00e9m.</p> <p><pre><code>curl -X POST \\\n-H \"Content-Type: application/json\" \\\n-d '{\"name\":\"Insper\"}' \\\n\"https://&lt;id&gt;.execute-api.us-east-1.amazonaws.com/dev/hello\"\n/\\\n          ||\nSubstitua &lt;id&gt; pelo seu id\n</code></pre> </p> <p> Dica visual</p> <p>Se entrarmos no dashboard do CloudWatch, conseguiremos ver os logs de acesso registrados para nossas solicita\u00e7\u00f5es. </p>"},{"location":"#criando-funcao-lambda-com-dependencias-externas-e-acesso-ao-bucket-s3","title":"Criando fun\u00e7\u00e3o lambda com depend\u00eancias externas e acesso ao bucket S3","text":"<p>Vamos agora criar outra fun\u00e7\u00e3o lambda com depend\u00eancias externas e que garanta acesso para a leitura de um arquivo em um bucket S3.</p> <p>Novamente, utilizaremos o random pet para nos auxiliar com um nome aleat\u00f3rio e \u00fanico para nosso bucket do S3 e dicionaremos o prefixo \"test\" (o que tamb\u00e9m auxilia na identifica\u00e7\u00e3o do bucket).</p> <p>Para esse bucket tamb\u00e9m deixaremos o acesso p\u00fablico desativado.</p> terraform/test-bucket.tf <pre><code>resource \"random_pet\" \"test_bucket_name\" {\nprefix = \"test\"\nlength = 2\n}\n\nresource \"aws_s3_bucket\" \"test\" {\nbucket        = random_pet.test_bucket_name.id\nforce_destroy = true\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"test\" {\nbucket = aws_s3_bucket.test.id\n\nblock_public_acls       = true\nblock_public_policy     = true\nignore_public_acls      = true\nrestrict_public_buckets = true\n}\n</code></pre> <p>N\u00f3s tamb\u00e9m podemos criar um objeto no S3 bucket utilizando terraform e o jsoncode build-in. Isso ir\u00e1 converter para um objeto json v\u00e1lido.</p> terraform/test-bucket.tf <pre><code>resource \"random_pet\" \"test_bucket_name\" {\nprefix = \"test\"\nlength = 2\n}\n\nresource \"aws_s3_bucket\" \"test\" {\nbucket        = random_pet.test_bucket_name.id\nforce_destroy = true\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"test\" {\nbucket = aws_s3_bucket.test.id\n\nblock_public_acls       = true\nblock_public_policy     = true\nignore_public_acls      = true\nrestrict_public_buckets = true\n}\n\n+resource \"aws_s3_object\" \"test\" {\n+  bucket = aws_s3_bucket.test.id\n\n+  key     = \"hello.json\"\n+  content = jsonencode({ name = \"S3\" })\n+}\n\n+output \"test_s3_bucket\" {\n+  value = random_pet.test_bucket_name.id\n+}\n</code></pre> <p>Agora iremos criar uma nova fun\u00e7\u00e3o lambda em uma nova pasta s3.</p> <p>Come\u00e7aremos importando o aws-sdk e inicializando o objeto javascript.</p> <p>Essa fun\u00e7\u00e3o ir\u00e1 nos retornar o conte\u00fado do objeto.</p> s3/function.js <pre><code>const aws = require(\"aws-sdk\");\n\nconst s3 = new aws.S3({ apiVersion: \"2006-03-01\" });\n\nexports.handler = async (event, context) =&gt; {\nconsole.log(\"Received event:\", JSON.stringify(event, null, 2));\n\nconst bucket = event.bucket;\nconst object = event.object;\nconst key = decodeURIComponent(object.replace(/\\+/g, \" \"));\n\nconst params = {\nBucket: bucket,\nKey: key,\n};\ntry {\nconst { Body } = await s3.getObject(params).promise();\nconst content = Body.toString(\"utf-8\");\nreturn content + \" Yeah, I am working, Avelinux :) !!\";\n} catch (err) {\nconsole.log(err);\nconst message = `Error getting object ${key} from bucket ${bucket}.`;\nconsole.log(message);\nthrow new Error(message);\n}\n};\n</code></pre> <p>Dentro do diret\u00f3rio da rec\u00e9m-criada pasta \"s3\", devemos inicializar o projeto nodejs com o seguinte comando:</p> /s3 <pre><code>npm init\n</code></pre> <p>Esse comando ir\u00e1 gerar arquivos package.json com depend\u00eancias. N\u00e3o h\u00e1 necessidade de preencher as informa\u00e7\u00f5es solicitadas, basta teclar \"enter\" para cada info solicitada.</p> <p></p> <p>Em seguida, iremos instalar o m\u00f3dulo aws-sdk:</p> /s3 <p><pre><code>npm install aws-sdk\n</code></pre> </p> <p>Agora retornaremos \u00e0 pasta \"Terraform\" e iremos criar nossas pol\u00edticas de acesso.</p> terraform/s3-lambda.tf <pre><code>resource \"aws_iam_role\" \"s3_lambda_exec\" {\nname = \"s3-lambda\"\n\nassume_role_policy = &lt;&lt;POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"s3_lambda_policy\" {\nrole       = aws_iam_role.s3_lambda_exec.name\npolicy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_iam_policy\" \"test_s3_bucket_access\" {\nname        = \"TestS3BucketAccess\"\n\npolicy = jsonencode({\nVersion = \"2012-10-17\"\nStatement = [\n{\nAction = [\n\"s3:GetObject\", #Permitir obter um objeto do bucket\n]\nEffect   = \"Allow\"\nResource = \"arn:aws:s3:::${aws_s3_bucket.test.id}/*\"\n},\n]\n})\n}\n\n# Pol\u00edtica para acessar o novo bucket do s3:\n\nresource \"aws_iam_role_policy_attachment\" \"s3_lambda_test_s3_bucket_access\" {\nrole       = aws_iam_role.s3_lambda_exec.name\npolicy_arn = aws_iam_policy.test_s3_bucket_access.arn\n}\n\n# Aqui teremos apoio na extra\u00e7\u00e3o do aquivo zip da fun\u00e7\u00e3o\n\nresource \"aws_lambda_function\" \"s3\" {\nfunction_name = \"s3\"\n\ns3_bucket = aws_s3_bucket.lambda_bucket.id\ns3_key    = aws_s3_object.lambda_s3.key\n\nruntime = \"nodejs16.x\"\nhandler = \"function.handler\"\n\nsource_code_hash = data.archive_file.lambda_s3.output_base64sha256\n\nrole = aws_iam_role.s3_lambda_exec.arn\n}\n\n# Novo grupo de logs do CloudWatch para a fun\u00e7\u00e3o:\n\nresource \"aws_cloudwatch_log_group\" \"s3\" {\nname = \"/aws/lambda/${aws_lambda_function.s3.function_name}\"\n\nretention_in_days = 14\n}\n\n\n# \"Compacte a fun\u00e7\u00e3o e carregue o zip para o bucket s3:\"\n\ndata \"archive_file\" \"lambda_s3\" {\ntype = \"zip\"\n\nsource_dir  = \"../${path.module}/s3\"\noutput_path = \"../${path.module}/s3.zip\"\n}\n\nresource \"aws_s3_object\" \"lambda_s3\" {\nbucket = aws_s3_bucket.lambda_bucket.id\n\nkey    = \"s3.zip\"\nsource = data.archive_file.lambda_s3.output_path\n\nsource_hash = filemd5(data.archive_file.lambda_s3.output_path)\n}\n</code></pre> <p>Vamos agora deployar diretamente na m\u00e1quina local. Para isso ser\u00e1 necess\u00e1rio criar um simples script wrapper no Terraform:</p> terraform/terraform.sh <pre><code>#!/bin/sh\n\nset -e\n\ncd ../s3\nnpm ci\n\ncd ../terraform\nterraform apply\n</code></pre> <p>(No terminal, diret\u00f3rio /terraform) Vamos fazer o script se tornar execut\u00e1vel:</p> <pre><code>chmod +x terraform.sh\n</code></pre> <p>Em seguida podemos rodar:</p> <pre><code>./terraform.sh\n</code></pre> <p></p> <p>Note que, ao rodarmos o comando acima, ele automaticamente rodar\u00e1 nosso terraform.sh que possui um \"terraform apply\", aplicando imediatamente as altera\u00e7\u00f5es que fizemos, sem que tenhamos que utilizar novamente o comando \"terraform apply\" no terminal.</p> <p>No terminal receberemos de volta o nome do nosso rec\u00e9m-criado bucket do s3. Podemos invocar essa fun\u00e7\u00e3o s3 com o nome do bucket + nosso objeto para ver se o lambda conseguir\u00e1 obter o objeto do bucket.</p> <pre><code>aws lambda invoke \\\n--region=us-east-1 \\\n--function-name=s3 \\\n--cli-binary-format raw-in-base64-out \\\n--payload '{\"bucket\":\"test-&lt;your&gt;-&lt;name&gt;\",\"object\":\"hello.json\"}' \\\nresponse.json\n                             /\\\n||\nSubstitua test-&lt;your&gt;-&lt;name&gt; pelo nome do seu bucket\n</code></pre> <p>Por fim, rode no terminal o seguinte comando:</p> <pre><code>cat responde.json\n</code></pre> <p></p> <p>Se voc\u00ea receber como retorno Yeah, I am working, Avelinux :), parab\u00e9ns, voc\u00ea concluiu sua aplica\u00e7\u00e3o e ela est\u00e1 funcionando!</p> <p>Agora que voc\u00ea j\u00e1 viu todo o ambiente da sua IaaC (Infrastructure as a Code) sendo criado e funcionando, chegou a hora de destru\u00ed-lo!</p> <p>Utilize o comando a seguir no seu terminal para destruir a infraestrutura: <pre><code>terraform destroy\n</code></pre> O resultado final deve ser algo parecido com a imagem a seguir:</p> <p></p> <p> Dica visual</p> <p>Entre no dashboard da AWS e veja que todos os recursos sumiram: eles foram destruidos!</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Foram utilizadas dezenas de refer\u00eancias \u00e0 constru\u00e7\u00e3o do conhecimento aplicado aqui neste material. Todo o conte\u00fado utilizado para a constru\u00e7\u00e3o do aprendizado pode ser conferido abaixo:</p> <ol> <li>Publish/Subscribe on AWS with Terraform, .NET 6 and serverless</li> <li>CodePossibility thumbnail generation lambda</li> <li>Application Integration Patterns</li> <li>AWS: Serverless web application</li> <li>Build Lambda based REST API</li> <li>Terraform: Serverless (Node.js) REST API Tutorial - 1</li> <li>Terraform: Serverless (Node.js) REST API Tutorial - 2</li> <li>Build a serverless REST API with .NET 6 and Terraform</li> <li>AWS Serverless Application with Lambda, API gateway, GoLang and Terraform</li> <li>AWS Invoke</li> <li>facebook/create-react-app</li> <li>chgasparoto/curso-aws-com-terraform</li> <li>DevOps: AWS com Terraform Automatizando sua infraestrutura</li> <li>Serverless AWS Amplify Apps with Terraform and AWS</li> <li>Terraform Command: version</li> <li>Terraform Real World Use Case</li> <li>O que \u00e9 e para que serve o AWS S3 e Buckets ?</li> </ol>"}]}